from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
from datetime import datetime
from urllib.parse import unquote, urlparse, parse_qs
import re

# Inputs
BUSQUEDA = input("ğŸ” Â¿QuÃ© querÃ©s buscar? (ej: bmw): ").strip()
try:
    LIMITE = int(input("â± Â¿CuÃ¡ntos autos querÃ©s scrapear? (0 = sin lÃ­mite): ").strip())
except ValueError:
    LIMITE = 0

BASE_URL = f"https://listado.mercadolibre.com.uy/{BUSQUEDA.replace(' ', '-')}"
ARCHIVO = f"autos_{BUSQUEDA}_detallado.xlsx"
FECHA_EXTRACCION = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

driver = webdriver.Chrome()
driver.get(BASE_URL)

resultados = []
pagina = 1
total_scrapeados = 0

def scroll_hasta_el_final():
    SCROLL_PAUSA = 1.5
    altura_anterior = 0
    while True:
        altura_actual = driver.execute_script("return document.body.scrollHeight")
        if altura_actual == altura_anterior:
            break
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSA)
        altura_anterior = altura_actual

while True:
    print(f"ğŸŒ Procesando pÃ¡gina {pagina}...")

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "ui-search-layout__item"))
        )
    except:
        print("â›” No se encontraron productos.")
        break

    scroll_hasta_el_final()
    time.sleep(1)

    contenedores = driver.find_elements(By.CLASS_NAME, "ui-search-layout__item")
    print(f"ğŸ” Detectados {len(contenedores)} autos en pÃ¡gina {pagina}")

    links = []
    for contenedor in contenedores:
        try:
            raw_link = contenedor.find_element(By.CLASS_NAME, "poly-component__title").get_attribute("href")
            if "redirect?" in raw_link and "redirect_url=" in raw_link:
                params = parse_qs(urlparse(raw_link).query)
                link = unquote(params["redirect_url"][0])
            else:
                link = raw_link.split('?')[0]
            links.append(link)
        except:
            continue

    for link in links:
        if LIMITE and total_scrapeados >= LIMITE:
            break

        try:
            driver.get(link)
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(2)

            titulo = driver.find_element(By.TAG_NAME, "h1").text
            precio = driver.find_element(By.CLASS_NAME, "andes-money-amount__fraction").text

            # âœ… UBICACIÃ“N real desde el <p> correcto
            try:
                parrafos = driver.find_elements(By.TAG_NAME, "p")
                ubicacion = "No disponible"
                for p in parrafos:
                    clase = p.get_attribute("class")
                    if clase and "ui-pdp-media__title" in clase:
                        texto = p.text.strip()
                        if texto.lower().startswith("el vehÃ­culo estÃ¡ en"):
                            ubicacion = texto.replace("El vehÃ­culo estÃ¡ en", "").strip()
                            break
            except:
                ubicacion = "No disponible"

            aÃ±o = kilometraje = color = motor = combustible = transmision = fecha_publicacion = "No disponible"

            try:
                specs = driver.find_elements(By.CLASS_NAME, "ui-vpp-highlighted-specs__key-value__labels__key-value")
                for spec in specs:
                    spans = spec.find_elements(By.TAG_NAME, "span")
                    if len(spans) >= 2:
                        campo = spans[0].text.lower().strip().rstrip(":")
                        valor = spans[1].text.strip()
                        if "color" in campo:
                            color = valor
                        elif "motor" in campo:
                            motor = valor
                        elif "combustible" in campo:
                            combustible = valor
                        elif "transmisiÃ³n" in campo or "transmision" in campo:
                            transmision = valor
            except:
                pass

            try:
                detalle = driver.find_element(By.CLASS_NAME, "ui-pdp-subtitle").text
                if "publicado" in detalle.lower():
                    partes = re.split(r"[\|Â·]", detalle)
                    for p in partes:
                        p = p.strip()
                        if re.fullmatch(r"\d{4}", p):
                            aÃ±o = p
                        elif "km" in p.lower():
                            kilometraje = p
                        elif "publicado" in p.lower():
                            fecha_publicacion = p
            except:
                pass

            resultados.append({
                "TÃ­tulo": titulo,
                "Precio": precio,
                "UbicaciÃ³n": ubicacion,
                "AÃ±o": aÃ±o,
                "Kilometraje": kilometraje,
                "Color": color,
                "Motor": motor,
                "Combustible": combustible,
                "TransmisiÃ³n": transmision,
                "FechaPublicaciÃ³n": fecha_publicacion,
                "FechaScraping": FECHA_EXTRACCION,
                "Link": link
            })

            total_scrapeados += 1
            print(f"âœ… ({total_scrapeados}) {titulo}")
        except Exception as e:
            print(f"âŒ FallÃ³ en {link}: {e}")
            continue

    if LIMITE and total_scrapeados >= LIMITE:
        print("â¹ Se alcanzÃ³ el lÃ­mite.")
        break

    try:
        siguiente_li = driver.find_element(By.CSS_SELECTOR, "li.andes-pagination__button--next")
        if "disabled" in siguiente_li.get_attribute("class"):
            print("ğŸ No hay mÃ¡s pÃ¡ginas.")
            break
        siguiente_btn = siguiente_li.find_element(By.TAG_NAME, "a")
        driver.execute_script("arguments[0].scrollIntoView();", siguiente_btn)
        time.sleep(1)
        siguiente_btn.click()
        pagina += 1
        time.sleep(3)
    except:
        print("ğŸ Fin del paginado.")
        break

driver.quit()

# ğŸ“¦ Guardar en Excel
df = pd.DataFrame(resultados)
df.to_excel(ARCHIVO, index=False)
print(f"\nğŸ“„ Se guardaron {len(df)} autos en '{ARCHIVO}'")
